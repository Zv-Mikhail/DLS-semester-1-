{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lmqhuY5wi0d"
   },
   "source": [
    "\n",
    "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Домашнее задание. Классификация изображений</b></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw7YkEefehWo"
   },
   "source": [
    "# Домашнее задание. Классификация изображений\n",
    "\n",
    "Сегодня вам предстоить помочь телекомпании FOX в обработке их контента. Как вы знаете, сериал \"Симпсоны\" идет на телеэкранах более 25 лет, и за это время скопилось очень много видеоматериала. Персоонажи менялись вместе с изменяющимися графическими технологиями, и Гомер Симпсон-2018 не очень похож на Гомера Симпсона-1989. В этом задании вам необходимо классифицировать персонажей, проживающих в Спрингфилде. Думаю, нет смысла представлять каждого из них в отдельности.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecl2I3jcver5"
   },
   "source": [
    "В нашем тесте будет 991 картинка, для которых вам будет необходимо предсказать класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG47vhLxKNln"
   },
   "source": [
    "## Шаг 1. Установка зависимостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYzxwh-yfrOI"
   },
   "source": [
    "#### Установим необходимые библиотеки и проверим доступность CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:08:55.206933Z",
     "iopub.status.busy": "2025-11-08T13:08:55.206335Z",
     "iopub.status.idle": "2025-11-08T13:08:59.081948Z",
     "shell.execute_reply": "2025-11-08T13:08:59.081113Z",
     "shell.execute_reply.started": "2025-11-08T13:08:55.206911Z"
    },
    "id": "WWgcwKwCLBfr",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "# we will verify that GPU is enabled for this notebook\n",
    "# following should print: CUDA is available!  Training on GPU ...\n",
    "#\n",
    "# if it prints otherwise, then you need to enable GPU:\n",
    "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T08:45:16.414201Z",
     "iopub.status.busy": "2025-11-08T08:45:16.413935Z",
     "iopub.status.idle": "2025-11-08T08:45:16.538667Z",
     "shell.execute_reply": "2025-11-08T08:45:16.537810Z",
     "shell.execute_reply.started": "2025-11-08T08:45:16.414183Z"
    },
    "id": "GvWhlkiRMxih",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:18:39.664959Z",
     "iopub.status.busy": "2025-11-08T13:18:39.664669Z",
     "iopub.status.idle": "2025-11-08T13:18:39.671835Z",
     "shell.execute_reply": "2025-11-08T13:18:39.670943Z",
     "shell.execute_reply.started": "2025-11-08T13:18:39.664937Z"
    },
    "id": "naD6xsZzMxrC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import torchsummary\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import random, numpy as np, os\n",
    "\n",
    "# в sklearn не все гладко, чтобы в colab удобно выводить картинки\n",
    "# мы будем игнорировать warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ifNrsREjHTH"
   },
   "source": [
    " #### Определим константы, которые будем использовать в по ходу ноутбука"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:09:36.022263Z",
     "iopub.status.busy": "2025-11-08T13:09:36.021828Z",
     "iopub.status.idle": "2025-11-08T13:09:36.027493Z",
     "shell.execute_reply": "2025-11-08T13:09:36.026679Z",
     "shell.execute_reply.started": "2025-11-08T13:09:36.022239Z"
    },
    "id": "WTdzMtgJP15N",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# разные режимы датасета\n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "\n",
    "# работаем на видеокарте\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "PATH = '/kaggle/input/journey-to-springfield1'\n",
    "#определим директории с тренировочными и тестовыми файлами\n",
    "TRAIN_DIR = Path(f'{PATH}/train') #Path('./data/train/')\n",
    "TEST_DIR = Path(f'{PATH}/testset') #Path('./data/testset')\n",
    "\n",
    "# параметры нормировки изображений по трем каналам перед подачей в модель\n",
    "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
    "NORMALIZE_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIlnzsxOgU5-"
   },
   "source": [
    "## Шаг 2. Загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkKownjFi2L9"
   },
   "source": [
    "#### Скачаем изображения по ссылке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hmy-R9YjDcp"
   },
   "source": [
    "Посмотрите на структуру файлов в папках train и testset.\n",
    "\n",
    "В train лежат данные, которые мы будем использовать для обучения модели. Изображения персонажей разложены по папкам, которые названы по именам персонажей. Названия папок мы в дальнейшем будет использовать в качестве текстовых меток классов.\n",
    "\n",
    "В testset находятся изображения, для которых вам надо будет сделать прогноз наиболее вероятного класса.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sANBgBHwiKIe"
   },
   "source": [
    "Для обращения к файлам сформируем списки имен файлов обучающей+валидационнной и тестовой выборок. Это полные имена, включающие путь к файлам.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:09:40.901894Z",
     "iopub.status.busy": "2025-11-08T13:09:40.901254Z",
     "iopub.status.idle": "2025-11-08T13:10:53.741456Z",
     "shell.execute_reply": "2025-11-08T13:10:53.740788Z",
     "shell.execute_reply.started": "2025-11-08T13:09:40.901872Z"
    },
    "id": "yUhzOq1zRJil",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:10:53.742812Z",
     "iopub.status.busy": "2025-11-08T13:10:53.742578Z",
     "iopub.status.idle": "2025-11-08T13:10:53.747662Z",
     "shell.execute_reply": "2025-11-08T13:10:53.746832Z",
     "shell.execute_reply.started": "2025-11-08T13:10:53.742787Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 20933\n",
      "Test files: 991\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train files: {len(train_val_files)}\")\n",
    "print(f\"Test files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrAipHKmiUzJ"
   },
   "source": [
    "Кодировать имена персонажей в числовые метки класса и обратно будем при помощи `LabelEncoder`.\n",
    "\n",
    "Для train выборки сформируем список текстовых меток всех изображений - имя родительской директории, которая одновременно является и именем персонажа. Зададим числовые метки классов нашего энкодера при помощи метода `fit`.\n",
    "\n",
    "Далее будем применять метод `transform` для преобразования текстовых меток в числовые, и метод `inverse_transform` для преобразования числовых меток в текстовые.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:10.254149Z",
     "iopub.status.busy": "2025-11-08T13:11:10.253299Z",
     "iopub.status.idle": "2025-11-08T13:11:10.291180Z",
     "shell.execute_reply": "2025-11-08T13:11:10.290593Z",
     "shell.execute_reply.started": "2025-11-08T13:11:10.254119Z"
    },
    "id": "4U52VSWugb9m",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "\n",
    "label_encoder.fit(train_val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kS5d6SFFiwIO"
   },
   "source": [
    "Разделим train выборку на обучающую и валидационнную части. Для того, чтобы персонажи были пропорционально представлены в обучающей и валидационнной подвыборках, применим стратификацию по меткам класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:13.713657Z",
     "iopub.status.busy": "2025-11-08T13:11:13.713038Z",
     "iopub.status.idle": "2025-11-08T13:11:13.854004Z",
     "shell.execute_reply": "2025-11-08T13:11:13.853433Z",
     "shell.execute_reply.started": "2025-11-08T13:11:13.713634Z"
    },
    "id": "TmPhhKKlRyCF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
    "                                          stratify=train_val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSYDxPP9lb8a"
   },
   "source": [
    "#### Создадим Datasets и Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGBOwkrQc8BK"
   },
   "source": [
    "Важно разобраться, что делает метод self.transform_images_to_tensors().\n",
    "\n",
    "`Compose` объединяет последовательность следующих преобразований:\n",
    "- `PILToTensor` конвертирует  `PIL Image` в тензор с параметрами в диапазоне $[0, 255]$ (как все пиксели в исходном изображении)\n",
    "- `ToDtype` преобразует тензор в `FloatTensor` размера ($C \\times H \\times W$) со значениями пикселей в диапазоне $[0,1]$\n",
    "- затем `Normalize` производится масштабирование:\n",
    "$\\text{input} = \\frac{\\text{input} - \\text{mean}}{\\text{std}} $, <br>      где константы mean и std - средние и дисперсии по каналам в датасете ImageNet\n",
    "- наконец, `Resize` преобразует картинки к размеру $224 \\times 224$ (в описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следует привести их к одному размеру).\n",
    "\n",
    "Сейчас аугментация не изображений не производится, поэтому для обучающих и валидационных/тестовых изображений производится одинаковая трансформация. В дальнейшем, если вы захотите добавить аугментацию, вы можете сделать это, например, модифицировав метод `transform_images_to_tensors`. Подробнее про трансформацию изображений вы можете почитать в документации: https://docs.pytorch.org/vision/main/transforms.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:27.557318Z",
     "iopub.status.busy": "2025-11-08T13:11:27.556668Z",
     "iopub.status.idle": "2025-11-08T13:11:27.568001Z",
     "shell.execute_reply": "2025-11-08T13:11:27.567140Z",
     "shell.execute_reply.started": "2025-11-08T13:11:27.557293Z"
    },
    "id": "YZQLgR07-u5Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "    def __init__(self, files, label_encoder, mode, augment_type='basic'):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.label_encoder = label_encoder\n",
    "        self.len_ = len(self.files)\n",
    "\n",
    "        self.augment_type = augment_type  # <- флажок для аугументации\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_ # сейчас self.__len__() возвращает количество картинок, подаваемых на вход.\n",
    "        # Если вы решите перевзвесить размеры категорий внутри класса -\n",
    "        # не забудьте изменить вывод self.__len__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.load_image(self.files[index])\n",
    "        x = self.transform_images_to_tensors(x)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            path = self.files[index]\n",
    "            y = self.label_encoder.transform([path.parent.name,]).item()\n",
    "            return x, y\n",
    "\n",
    "    # принимает путь к файлу изображения и возвращает само изображение\n",
    "    def load_image(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "\n",
    "    # преобразует изображение в тензор\n",
    "    def transform_images_to_tensors(self, image):\n",
    "      if self.mode == 'train':\n",
    "        if self.augment_type == 'basic':\n",
    "            transform = v2.Compose([\n",
    "                v2.Resize(RESCALE_SIZE),\n",
    "                v2.PILToTensor(),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
    "                \n",
    "            ])\n",
    "        elif self.augment_type == 'custom':\n",
    "            transform = v2.Compose([\n",
    "            v2.Resize(RESCALE_SIZE),\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            v2.RandomRotation(degrees=15),\n",
    "            v2.ColorJitter(\n",
    "                brightness=0.2,\n",
    "                contrast=0.2,\n",
    "                saturation=0.1\n",
    "            ),\n",
    "            v2.PILToTensor(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
    "            ])\n",
    "        \n",
    "      else:\n",
    "        transform = v2.Compose([\n",
    "            v2.Resize(RESCALE_SIZE),\n",
    "            v2.PILToTensor(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
    "            \n",
    "          ])\n",
    "\n",
    "      tensor_transformed = transform(image)\n",
    "      return(tensor_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:41.655698Z",
     "iopub.status.busy": "2025-11-08T13:11:41.655104Z",
     "iopub.status.idle": "2025-11-08T13:11:41.745457Z",
     "shell.execute_reply": "2025-11-08T13:11:41.744621Z",
     "shell.execute_reply.started": "2025-11-08T13:11:41.655677Z"
    },
    "id": "EYf0sOM0P8RE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpsonsDataset(train_files, label_encoder = label_encoder, mode='train', augment_type='custom')\n",
    "val_dataset = SimpsonsDataset(val_files, label_encoder, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:45.384692Z",
     "iopub.status.busy": "2025-11-08T13:11:45.384185Z",
     "iopub.status.idle": "2025-11-08T13:11:45.388118Z",
     "shell.execute_reply": "2025-11-08T13:11:45.387415Z",
     "shell.execute_reply.started": "2025-11-08T13:11:45.384670Z"
    },
    "id": "lcyod0SRQzHZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:46.987575Z",
     "iopub.status.busy": "2025-11-08T13:11:46.986824Z",
     "iopub.status.idle": "2025-11-08T13:11:46.991781Z",
     "shell.execute_reply": "2025-11-08T13:11:46.991112Z",
     "shell.execute_reply.started": "2025-11-08T13:11:46.987552Z"
    },
    "id": "YB6GX4O1QAcQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "loaders = {'train':train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMm7fq0fU4dQ"
   },
   "source": [
    "Напишите функции:\n",
    "- для обучения модели на одной эпохе\n",
    "- для валидации модели на одной эпохе\n",
    "- для реализации полного цикла обучения\n",
    "\n",
    "За основу можно взять функции, которые вы написали в предыдущем домашнем задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:50.953648Z",
     "iopub.status.busy": "2025-11-08T13:11:50.953088Z",
     "iopub.status.idle": "2025-11-08T13:11:50.959721Z",
     "shell.execute_reply": "2025-11-08T13:11:50.959036Z",
     "shell.execute_reply.started": "2025-11-08T13:11:50.953626Z"
    },
    "id": "82VxfH7TY5AP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_one_epoch(model, dataloader, loss_func, optimizer, device):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: модель PyTorch\n",
    "        dataloader: DataLoader с обучающей выборкой\n",
    "        loss_func: функция потерь\n",
    "        optimizer: оптимизатор\n",
    "        device: 'cpu', 'cuda' или 'mps'\n",
    "    \n",
    "    Returns:\n",
    "        epoch_loss, epoch_acc, epoch_f1, all_preds, all_labels\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc='Training', leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(all_labels)\n",
    "    epoch_acc = (all_preds == all_labels).sum().item() / len(all_labels)\n",
    "    epoch_f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average='micro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:52.972551Z",
     "iopub.status.busy": "2025-11-08T13:11:52.972268Z",
     "iopub.status.idle": "2025-11-08T13:11:52.978921Z",
     "shell.execute_reply": "2025-11-08T13:11:52.978128Z",
     "shell.execute_reply.started": "2025-11-08T13:11:52.972531Z"
    },
    "id": "a7Yu-OU6Y51Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def val_one_epoch(model, dataloader, loss_func, device):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: модель PyTorch\n",
    "        dataloader: DataLoader с валидационной выборкой\n",
    "        loss_func: функция потерь\n",
    "        device: 'cpu', 'cuda' или 'mps'\n",
    "    \n",
    "    Returns:\n",
    "        epoch_loss, epoch_acc, epoch_f1, all_preds, all_labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Validation', leave=False):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(all_labels)\n",
    "    epoch_acc = (all_preds == all_labels).sum().item() / len(all_labels)\n",
    "    epoch_f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average='micro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:11:56.011176Z",
     "iopub.status.busy": "2025-11-08T13:11:56.010850Z",
     "iopub.status.idle": "2025-11-08T13:11:56.018474Z",
     "shell.execute_reply": "2025-11-08T13:11:56.017612Z",
     "shell.execute_reply.started": "2025-11-08T13:11:56.011152Z"
    },
    "id": "s5hf0EnVY5rn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss_func, optimizer, num_epochs=10, device=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: PyTorch модель\n",
    "        train_loader: DataLoader для обучения\n",
    "        val_loader: DataLoader для валидации\n",
    "        loss_func: функция потерь\n",
    "        optimizer: оптимизатор\n",
    "        num_epochs: количество эпох\n",
    "        device: 'cpu', 'cuda' или 'mps'. Если None, выбирается автоматически.\n",
    "    \n",
    "    Returns:\n",
    "        model: обученная модель\n",
    "        history: словарь с историей метрик\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \n",
    "                              \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f\"Training on device: {device}\")\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"train_f1\": [],\n",
    "               \"val_loss\": [], \"val_acc\": [], \"val_f1\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Тренировка \n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, loss_func, optimizer, device)\n",
    "        \n",
    "        #Валидация\n",
    "        val_loss, val_acc, val_f1 = val_one_epoch(model, val_loader, loss_func, device)\n",
    "\n",
    "        # Вывод\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "\n",
    "        #Сохранение истории\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"train_f1\"].append(train_f1)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_f1\"].append(val_f1)\n",
    "\n",
    "        #Сохраняем лучшую модель по F1\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    print(f\"\\nBest Validation F1: {best_f1:.4f}\")\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "вобще можно было выводить только accuracy или f1-score(micro) - т.к. это одно и тоже, но пусть будет) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEWTL6jgdh7L"
   },
   "source": [
    "## Шаг 6. Submit на Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYKhQ6l6GmGf"
   },
   "source": [
    "Создадим loader для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T15:21:25.883358Z",
     "iopub.status.busy": "2025-11-08T15:21:25.882709Z",
     "iopub.status.idle": "2025-11-08T15:21:25.887512Z",
     "shell.execute_reply": "2025-11-08T15:21:25.886801Z",
     "shell.execute_reply.started": "2025-11-08T15:21:25.883333Z"
    },
    "id": "9UTbU0Zbc6Hb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = SimpsonsDataset(test_files, label_encoder = label_encoder, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqbzkJpzG-4_"
   },
   "source": [
    "Воспользуемся функцией predict, которая возвращает предсказанные числовые метки для всех объектов в лоадере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T15:21:28.720100Z",
     "iopub.status.busy": "2025-11-08T15:21:28.719730Z",
     "iopub.status.idle": "2025-11-08T15:21:28.725607Z",
     "shell.execute_reply": "2025-11-08T15:21:28.724872Z",
     "shell.execute_reply.started": "2025-11-08T15:21:28.720074Z"
    },
    "id": "TEQfNcJl03Fo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    all_predictions = torch.tensor([]).to(DEVICE).int()\n",
    "    print(\"Test mode...\")\n",
    "    for inputs in tqdm_notebook(loader):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            predictions = outputs.argmax(-1).int()\n",
    "            all_predictions = torch.cat((all_predictions, predictions), 0)\n",
    "    return all_predictions.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-O2dTb3HoGY"
   },
   "source": [
    "Получем предсказание меток классов для тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T15:21:43.780539Z",
     "iopub.status.busy": "2025-11-08T15:21:43.780007Z",
     "iopub.status.idle": "2025-11-08T15:21:53.601953Z",
     "shell.execute_reply": "2025-11-08T15:21:53.601213Z",
     "shell.execute_reply.started": "2025-11-08T15:21:43.780503Z"
    },
    "id": "1IrfkpZP2F8R",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mode...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33256bf709764980ba4eeca869b2666b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_numeric_labels = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YamegDlyH4tt"
   },
   "source": [
    "и преобразуем их в текстовые метки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T15:21:55.599960Z",
     "iopub.status.busy": "2025-11-08T15:21:55.599234Z",
     "iopub.status.idle": "2025-11-08T15:21:55.604354Z",
     "shell.execute_reply": "2025-11-08T15:21:55.603757Z",
     "shell.execute_reply.started": "2025-11-08T15:21:55.599927Z"
    },
    "id": "tYyVB2Z234g1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_text_labels = label_encoder.inverse_transform(predicted_numeric_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IECE3-CoIoQ-"
   },
   "source": [
    "Загрузим пример файла для загрузки на Kaggle (проверьте путь, по которому у вас лежит файл sample_submission.csv и при необходимости скорректируйте путь в коде ниже):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "execution": {
     "iopub.execute_input": "2025-11-08T15:23:22.452880Z",
     "iopub.status.busy": "2025-11-08T15:23:22.452183Z",
     "iopub.status.idle": "2025-11-08T15:23:22.486544Z",
     "shell.execute_reply": "2025-11-08T15:23:22.485819Z",
     "shell.execute_reply.started": "2025-11-08T15:23:22.452856Z"
    },
    "id": "yw0zZ-Hdd89s",
    "outputId": "c294cd08-b5b0-4751-c4a3-a13a457944f1",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img0.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img8.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img9.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id      Expected\n",
       "0  img0.jpg  bart_simpson\n",
       "1  img1.jpg  bart_simpson\n",
       "2  img2.jpg  bart_simpson\n",
       "3  img3.jpg  bart_simpson\n",
       "4  img4.jpg  bart_simpson\n",
       "5  img5.jpg  bart_simpson\n",
       "6  img6.jpg  bart_simpson\n",
       "7  img7.jpg  bart_simpson\n",
       "8  img8.jpg  bart_simpson\n",
       "9  img9.jpg  bart_simpson"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv(\"/kaggle/input/journey-to-springfield1/sample_submission.csv\")\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T15:23:25.477831Z",
     "iopub.status.busy": "2025-11-08T15:23:25.477294Z",
     "iopub.status.idle": "2025-11-08T15:23:25.486657Z",
     "shell.execute_reply": "2025-11-08T15:23:25.485743Z",
     "shell.execute_reply.started": "2025-11-08T15:23:25.477808Z"
    },
    "id": "maK18KSIDzDP",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img0.jpg</td>\n",
       "      <td>nelson_muntz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>ned_flanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img100.jpg</td>\n",
       "      <td>chief_wiggum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img101.jpg</td>\n",
       "      <td>apu_nahasapeemapetilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img102.jpg</td>\n",
       "      <td>kent_brockman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img103.jpg</td>\n",
       "      <td>edna_krabappel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img104.jpg</td>\n",
       "      <td>chief_wiggum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img105.jpg</td>\n",
       "      <td>lisa_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img106.jpg</td>\n",
       "      <td>kent_brockman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                Expected\n",
       "0    img0.jpg            nelson_muntz\n",
       "1    img1.jpg            bart_simpson\n",
       "2   img10.jpg            ned_flanders\n",
       "3  img100.jpg            chief_wiggum\n",
       "4  img101.jpg  apu_nahasapeemapetilon\n",
       "5  img102.jpg           kent_brockman\n",
       "6  img103.jpg          edna_krabappel\n",
       "7  img104.jpg            chief_wiggum\n",
       "8  img105.jpg            lisa_simpson\n",
       "9  img106.jpg           kent_brockman"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = pd.DataFrame({'Id': [path.name for path in test_files], 'Expected': predicted_text_labels})\n",
    "my_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T15:23:59.934549Z",
     "iopub.status.busy": "2025-11-08T15:23:59.933657Z",
     "iopub.status.idle": "2025-11-08T15:23:59.940526Z",
     "shell.execute_reply": "2025-11-08T15:23:59.939901Z",
     "shell.execute_reply.started": "2025-11-08T15:23:59.934511Z"
    },
    "id": "5rdlyMKtiYe2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "my_submission.to_csv('/kaggle/working/mixup50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собственные эксперементы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с даннымм "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас явно присутсвует дизбаланс в обучающейся выборке, посмотрим какой и потом попробуем его исправить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homer_simpson: 1684\n",
      "ned_flanders: 1090\n",
      "moe_szyslak: 1089\n",
      "lisa_simpson: 1015\n",
      "bart_simpson: 1006\n",
      "marge_simpson: 968\n",
      "krusty_the_clown: 904\n",
      "charles_montgomery_burns: 895\n",
      "principal_skinner: 895\n",
      "milhouse_van_houten: 809\n",
      "chief_wiggum: 739\n",
      "abraham_grampa_simpson: 685\n",
      "sideshow_bob: 658\n",
      "apu_nahasapeemapetilon: 467\n",
      "kent_brockman: 373\n",
      "comic_book_guy: 352\n",
      "edna_krabappel: 343\n",
      "nelson_muntz: 269\n",
      "lenny_leonard: 233\n",
      "mayor_quimby: 185\n",
      "waylon_smithers: 136\n",
      "maggie_simpson: 96\n",
      "groundskeeper_willie: 91\n",
      "barney_gumble: 80\n",
      "selma_bouvier: 77\n",
      "carl_carlson: 74\n",
      "ralph_wiggum: 67\n",
      "patty_bouvier: 54\n",
      "martin_prince: 53\n",
      "professor_john_frink: 49\n",
      "snake_jailbird: 41\n",
      "cletus_spuckler: 35\n",
      "rainier_wolfcastle: 34\n",
      "agnes_skinner: 32\n",
      "sideshow_mel: 30\n",
      "otto_mann: 24\n",
      "fat_tony: 20\n",
      "gil: 20\n",
      "miss_hoover: 13\n",
      "disco_stu: 6\n",
      "troy_mcclure: 6\n",
      "lionel_hutz: 2\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# достаём имена папок \n",
    "class_names = [path.parent.name for path in train_dataset.files]\n",
    "\n",
    "# считаем количество изображений каждого класса\n",
    "class_counts = Counter(class_names)\n",
    "\n",
    "# сортируем для наглядности\n",
    "for cls, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{cls}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T09:51:01.945433Z",
     "iopub.status.busy": "2025-11-08T09:51:01.944871Z",
     "iopub.status.idle": "2025-11-08T10:50:11.832521Z",
     "shell.execute_reply": "2025-11-08T10:50:11.831738Z",
     "shell.execute_reply.started": "2025-11-08T09:51:01.945403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/1895605242.py:48: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.1528 | Acc: 0.1410 | F1: 0.1410\n",
      "Val   Loss: 2.7414 | Acc: 0.2499 | F1: 0.2499\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1710 | Acc: 0.4124 | F1: 0.4124\n",
      "Val   Loss: 1.7581 | Acc: 0.5453 | F1: 0.5453\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3620 | Acc: 0.6265 | F1: 0.6265\n",
      "Val   Loss: 1.0688 | Acc: 0.7130 | F1: 0.7130\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9755 | Acc: 0.7336 | F1: 0.7336\n",
      "Val   Loss: 0.9811 | Acc: 0.7377 | F1: 0.7377\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7708 | Acc: 0.7879 | F1: 0.7879\n",
      "Val   Loss: 0.8436 | Acc: 0.7667 | F1: 0.7667\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6285 | Acc: 0.8235 | F1: 0.8235\n",
      "Val   Loss: 0.7698 | Acc: 0.7889 | F1: 0.7889\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5334 | Acc: 0.8484 | F1: 0.8484\n",
      "Val   Loss: 0.7286 | Acc: 0.8013 | F1: 0.8013\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4555 | Acc: 0.8691 | F1: 0.8691\n",
      "Val   Loss: 0.5153 | Acc: 0.8594 | F1: 0.8594\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4085 | Acc: 0.8834 | F1: 0.8834\n",
      "Val   Loss: 0.4906 | Acc: 0.8716 | F1: 0.8716\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3608 | Acc: 0.8958 | F1: 0.8958\n",
      "Val   Loss: 0.4803 | Acc: 0.8752 | F1: 0.8752\n",
      "\n",
      "Best Validation F1: 0.8752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Устройство \n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ResNet50 без загрузки предобученных весов \n",
    "model = models.resnet50(weights=None)  \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "#Оптимизатор\n",
    "lr_head = 1e-3\n",
    "lr_backbone = 1e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "backbone_params = []\n",
    "head_params = []\n",
    "for name, p in model.named_parameters():\n",
    "    if name.startswith(\"fc.\"):\n",
    "        head_params.append(p)\n",
    "    else:\n",
    "        backbone_params.append(p)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": backbone_params, \"lr\": lr_backbone},\n",
    "    {\"params\": head_params, \"lr\": lr_head}\n",
    "], weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "Обучение\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_func=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что как будто не хватило количесвто эпох, но даже если увеличить, не получится выбить скор 0.97+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:06:27.740094Z",
     "iopub.status.busy": "2025-11-08T13:06:27.739396Z",
     "iopub.status.idle": "2025-11-08T13:06:27.824763Z",
     "shell.execute_reply": "2025-11-08T13:06:27.824202Z",
     "shell.execute_reply.started": "2025-11-08T13:06:27.740072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpsonsDataset(train_files, label_encoder = label_encoder, mode='train', augment_type='custom') \n",
    "val_dataset = SimpsonsDataset(val_files, label_encoder, mode='val')\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "loaders = {'train':train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augment_type='custom' - добавление агументации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T11:11:47.342135Z",
     "iopub.status.busy": "2025-11-08T11:11:47.341599Z",
     "iopub.status.idle": "2025-11-08T11:55:27.214905Z",
     "shell.execute_reply": "2025-11-08T11:55:27.213970Z",
     "shell.execute_reply.started": "2025-11-08T11:11:47.342112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n",
      "\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4393 | Acc: 0.6217 | F1: 0.6217\n",
      "Val   Loss: 1.1834 | Acc: 0.6660 | F1: 0.6660\n",
      "\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9727 | Acc: 0.7291 | F1: 0.7291\n",
      "Val   Loss: 1.0421 | Acc: 0.7060 | F1: 0.7060\n",
      "\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8643 | Acc: 0.7561 | F1: 0.7561\n",
      "Val   Loss: 0.9954 | Acc: 0.7191 | F1: 0.7191\n",
      "\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7796 | Acc: 0.7765 | F1: 0.7765\n",
      "Val   Loss: 0.9672 | Acc: 0.7281 | F1: 0.7281\n",
      "\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7046 | Acc: 0.7944 | F1: 0.7944\n",
      "Val   Loss: 0.8983 | Acc: 0.7468 | F1: 0.7468\n",
      "\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6543 | Acc: 0.8050 | F1: 0.8050\n",
      "Val   Loss: 0.8468 | Acc: 0.7570 | F1: 0.7570\n",
      "\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6332 | Acc: 0.8113 | F1: 0.8113\n",
      "Val   Loss: 0.8342 | Acc: 0.7671 | F1: 0.7671\n",
      "\n",
      "Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5982 | Acc: 0.8210 | F1: 0.8210\n",
      "Val   Loss: 0.8605 | Acc: 0.7606 | F1: 0.7606\n",
      "\n",
      "Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5439 | Acc: 0.8366 | F1: 0.8366\n",
      "Val   Loss: 0.8304 | Acc: 0.7719 | F1: 0.7719\n",
      "\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5245 | Acc: 0.8402 | F1: 0.8402\n",
      "Val   Loss: 0.7774 | Acc: 0.7803 | F1: 0.7803\n",
      "\n",
      "Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5143 | Acc: 0.8439 | F1: 0.8439\n",
      "Val   Loss: 0.7490 | Acc: 0.7925 | F1: 0.7925\n",
      "\n",
      "Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4811 | Acc: 0.8541 | F1: 0.8541\n",
      "Val   Loss: 0.7884 | Acc: 0.7828 | F1: 0.7828\n",
      "\n",
      "Best Validation F1: 0.7925\n",
      "Training finished. Best model saved as 'best_model.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Параметры\n",
    "\n",
    "SEED = 42\n",
    "num_epochs = 12\n",
    "lr_head = 1e-3\n",
    "lr_backbone = 1e-4\n",
    "weight_decay = 1e-4\n",
    "model_path = \"best_resnet50.pth\"\n",
    "\n",
    "# Воспроизводимость и устройство\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \n",
    "                      \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# Модель с более сильным класификатором \n",
    "\n",
    "def build_resnet50(num_classes, pretrained=True, dropout_p=0.4):\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(in_features, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(dropout_p),\n",
    "        nn.Linear(1024, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = build_resnet50(num_classes=num_classes, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Оптимизатор\n",
    "backbone_params = [p for n,p in model.named_parameters() if not n.startswith(\"fc.\")]\n",
    "head_params = [p for n,p in model.named_parameters() if n.startswith(\"fc.\")]\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {\"params\": backbone_params, \"lr\": lr_backbone},\n",
    "    {\"params\": head_params, \"lr\": lr_head}\n",
    "], weight_decay=weight_decay)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#  Заморозка backbone \n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"fc.\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# Запуск обучения \n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_func=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Training finished. Best model saved as 'best_model.pth'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор получился ещё хуже( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T13:18:46.567867Z",
     "iopub.status.busy": "2025-11-08T13:18:46.567588Z",
     "iopub.status.idle": "2025-11-08T14:01:28.285780Z",
     "shell.execute_reply": "2025-11-08T14:01:28.285081Z",
     "shell.execute_reply.started": "2025-11-08T13:18:46.567847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n",
      "\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5967 | Acc: 0.8557 | F1: 0.8557\n",
      "Val   Loss: 0.2294 | Acc: 0.9431 | F1: 0.9431\n",
      "\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1268 | Acc: 0.9683 | F1: 0.9683\n",
      "Val   Loss: 0.1579 | Acc: 0.9606 | F1: 0.9606\n",
      "\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0805 | Acc: 0.9790 | F1: 0.9790\n",
      "Val   Loss: 0.1560 | Acc: 0.9627 | F1: 0.9627\n",
      "\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0509 | Acc: 0.9868 | F1: 0.9868\n",
      "Val   Loss: 0.1613 | Acc: 0.9635 | F1: 0.9635\n",
      "\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0317 | Acc: 0.9913 | F1: 0.9913\n",
      "Val   Loss: 0.1530 | Acc: 0.9679 | F1: 0.9679\n",
      "\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0361 | Acc: 0.9895 | F1: 0.9895\n",
      "Val   Loss: 0.1697 | Acc: 0.9627 | F1: 0.9627\n",
      "\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0261 | Acc: 0.9931 | F1: 0.9931\n",
      "Val   Loss: 0.1659 | Acc: 0.9641 | F1: 0.9641\n",
      "\n",
      "Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0248 | Acc: 0.9927 | F1: 0.9927\n",
      "Val   Loss: 0.1740 | Acc: 0.9656 | F1: 0.9656\n",
      "\n",
      "Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0352 | Acc: 0.9896 | F1: 0.9896\n",
      "Val   Loss: 0.1721 | Acc: 0.9648 | F1: 0.9648\n",
      "\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0267 | Acc: 0.9925 | F1: 0.9925\n",
      "Val   Loss: 0.1625 | Acc: 0.9671 | F1: 0.9671\n",
      "\n",
      "Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0171 | Acc: 0.9954 | F1: 0.9954\n",
      "Val   Loss: 0.1632 | Acc: 0.9669 | F1: 0.9669\n",
      "\n",
      "Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0181 | Acc: 0.9946 | F1: 0.9946\n",
      "Val   Loss: 0.1678 | Acc: 0.9664 | F1: 0.9664\n",
      "\n",
      "Best Validation F1: 0.9679\n",
      "Training finished. Best model saved as best_resnet50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = build_resnet50(num_classes=num_classes, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "backbone_params = [p for n,p in model.named_parameters() if not n.startswith(\"fc.\")]\n",
    "head_params = [p for n,p in model.named_parameters() if n.startswith(\"fc.\")]\n",
    "optimizer = optim.AdamW([\n",
    "    {\"params\": backbone_params, \"lr\": lr_backbone},\n",
    "    {\"params\": head_params, \"lr\": lr_head}\n",
    "], weight_decay=weight_decay)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_func=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Training finished. Best model saved as\", model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну вот, на конец-то хорошие результаты, продолжим эксперементы \n",
    "Попробую всё тоже самое, только не используя агументацию "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:33:06.389791Z",
     "iopub.status.busy": "2025-11-08T14:33:06.389265Z",
     "iopub.status.idle": "2025-11-08T14:33:06.480625Z",
     "shell.execute_reply": "2025-11-08T14:33:06.479843Z",
     "shell.execute_reply.started": "2025-11-08T14:33:06.389768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = SimpsonsDataset(train_files, label_encoder = label_encoder, mode='train', augment_type='custom')\n",
    "val_dataset = SimpsonsDataset(val_files, label_encoder, mode='val')\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "loaders = {'train':train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:09:06.538900Z",
     "iopub.status.busy": "2025-11-08T14:09:06.538218Z",
     "iopub.status.idle": "2025-11-08T14:29:57.776100Z",
     "shell.execute_reply": "2025-11-08T14:29:57.775308Z",
     "shell.execute_reply.started": "2025-11-08T14:09:06.538879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n",
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5268 | Acc: 0.8753 | F1: 0.8753\n",
      "Val   Loss: 0.1927 | Acc: 0.9559 | F1: 0.9559\n",
      "\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0609 | Acc: 0.9855 | F1: 0.9855\n",
      "Val   Loss: 0.1586 | Acc: 0.9616 | F1: 0.9616\n",
      "\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0138 | Acc: 0.9970 | F1: 0.9970\n",
      "Val   Loss: 0.1500 | Acc: 0.9643 | F1: 0.9643\n",
      "\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0056 | Acc: 0.9989 | F1: 0.9989\n",
      "Val   Loss: 0.1393 | Acc: 0.9696 | F1: 0.9696\n",
      "\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0050 | Acc: 0.9989 | F1: 0.9989\n",
      "Val   Loss: 0.1487 | Acc: 0.9689 | F1: 0.9689\n",
      "\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0159 | Acc: 0.9956 | F1: 0.9956\n",
      "Val   Loss: 0.2178 | Acc: 0.9480 | F1: 0.9480\n",
      "\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0372 | Acc: 0.9899 | F1: 0.9899\n",
      "Val   Loss: 0.2153 | Acc: 0.9509 | F1: 0.9509\n",
      "\n",
      "Best Validation F1: 0.9696\n",
      "Training finished. Best model saved as best_resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() #очищаем кэш\n",
    "\n",
    "#Пересоздаём модель и оптимизатор\n",
    "model = build_resnet50(num_classes=num_classes, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "backbone_params = [p for n,p in model.named_parameters() if not n.startswith(\"fc.\")]\n",
    "head_params = [p for n,p in model.named_parameters() if n.startswith(\"fc.\")]\n",
    "optimizer = optim.AdamW([\n",
    "    {\"params\": backbone_params, \"lr\": lr_backbone},\n",
    "    {\"params\": head_params, \"lr\": lr_head}\n",
    "], weight_decay=weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_func=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=7,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Training finished. Best model saved as\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аугментация всё таки приносила свои плоды, так что вернём её и попробуем метод mixup augmentation\n",
    "\n",
    "Но для этого надо немного изменить функции обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:35:42.821210Z",
     "iopub.status.busy": "2025-11-08T14:35:42.820617Z",
     "iopub.status.idle": "2025-11-08T14:35:42.833183Z",
     "shell.execute_reply": "2025-11-08T14:35:42.832408Z",
     "shell.execute_reply.started": "2025-11-08T14:35:42.821185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.4):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def train_one_epoch(model, dataloader, loss_func, optimizer, device, use_mixup=False, alpha=0.4):\n",
    "    model.train()\n",
    "    total_loss, total_correct, n = 0, 0, 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if use_mixup:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(images, labels, alpha)\n",
    "            outputs = model(mixed_x)\n",
    "            loss = mixup_criterion(loss_func, outputs, y_a, y_b, lam)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        if not use_mixup:\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            n += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_acc = total_correct / n if n > 0 else 0.0\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def evaluate_model(model, dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, n = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            n += labels.size(0)\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_acc = total_correct / n\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss_func, optimizer, num_epochs, device, scheduler=None, use_mixup=False):\n",
    "    best_val_acc = 0\n",
    "    history = {\"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, loss_func, optimizer, device, use_mixup=use_mixup)\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, loss_func, device)\n",
    "\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_mixup_model.pth\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\\n\")\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:36:19.617928Z",
     "iopub.status.busy": "2025-11-08T14:36:19.617380Z",
     "iopub.status.idle": "2025-11-08T15:19:26.771639Z",
     "shell.execute_reply": "2025-11-08T15:19:26.771013Z",
     "shell.execute_reply.started": "2025-11-08T14:36:19.617906Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "Train Loss: 1.3616 | Acc: 0.0000\n",
      "Val   Loss: 0.4134 | Acc: 0.9280\n",
      "\n",
      "Epoch 2/12\n",
      "Train Loss: 0.9398 | Acc: 0.0000\n",
      "Val   Loss: 0.3386 | Acc: 0.9463\n",
      "\n",
      "Epoch 3/12\n",
      "Train Loss: 0.9250 | Acc: 0.0000\n",
      "Val   Loss: 0.3251 | Acc: 0.9608\n",
      "\n",
      "Epoch 4/12\n",
      "Train Loss: 0.8001 | Acc: 0.0000\n",
      "Val   Loss: 0.2270 | Acc: 0.9706\n",
      "\n",
      "Epoch 5/12\n",
      "Train Loss: 0.7710 | Acc: 0.0000\n",
      "Val   Loss: 0.2010 | Acc: 0.9710\n",
      "\n",
      "Epoch 6/12\n",
      "Train Loss: 0.7609 | Acc: 0.0000\n",
      "Val   Loss: 0.1763 | Acc: 0.9771\n",
      "\n",
      "Epoch 7/12\n",
      "Train Loss: 0.7583 | Acc: 0.0000\n",
      "Val   Loss: 0.1818 | Acc: 0.9754\n",
      "\n",
      "Epoch 8/12\n",
      "Train Loss: 0.7043 | Acc: 0.0000\n",
      "Val   Loss: 0.1686 | Acc: 0.9782\n",
      "\n",
      "Epoch 9/12\n",
      "Train Loss: 0.6254 | Acc: 0.0000\n",
      "Val   Loss: 0.1353 | Acc: 0.9794\n",
      "\n",
      "Epoch 10/12\n",
      "Train Loss: 0.5963 | Acc: 0.0000\n",
      "Val   Loss: 0.1442 | Acc: 0.9803\n",
      "\n",
      "Epoch 11/12\n",
      "Train Loss: 0.6450 | Acc: 0.0000\n",
      "Val   Loss: 0.1545 | Acc: 0.9801\n",
      "\n",
      "Epoch 12/12\n",
      "Train Loss: 0.6309 | Acc: 0.0000\n",
      "Val   Loss: 0.1226 | Acc: 0.9815\n",
      "\n",
      "Training finished. Best model saved as best_resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() #очищаем кэш\n",
    "\n",
    "#Пересоздаём модель и оптимизатор\n",
    "model = build_resnet50(num_classes=num_classes, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "backbone_params = [p for n,p in model.named_parameters() if not n.startswith(\"fc.\")]\n",
    "head_params = [p for n,p in model.named_parameters() if n.startswith(\"fc.\")]\n",
    "optimizer = optim.AdamW([\n",
    "    {\"params\": backbone_params, \"lr\": lr_backbone},\n",
    "    {\"params\": head_params, \"lr\": lr_head}\n",
    "], weight_decay=weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_func=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    use_mixup=True   \n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Training finished. Best model saved as\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность на валидации немного выше, а вот на лидерборде такая же( - 0.99468\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем настоящую тяжёлую артилерию - ResNet152, если kaggle позволит)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу не позвол, и после перезапуска( стирание всех возможных кешей и загрухок, тоже)  \n",
    "Попытка 3 тоже не увенчалась успехом( Провал, ничего не помогло, поробуем ResNet101\n",
    "\n",
    "Эх на ResNet101 тоже памяти не хватило"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, моделек я попробовал куда больше, оставил только те, что прибавляли точность, а вот нервов потратил ещё больше на всякие либы для обучения зависимости и просто миллионы ошибо.\n",
    "\n",
    "Лучший скор показала модель resnet50 с аугментацией метод mixup на каких-то фотографиях показал себя лучше, а где то и хуже, судя из того, что скор остался таким же, хотя возможно всё дело в скрытой части лидербодра(5%)\n",
    "\n",
    "Ник на кагле - Михаил_Звягинцев_414906596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14060053,
     "isSourceIdPinned": false,
     "sourceId": 117426,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
